{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "218a2bdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\kavit\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\kavit\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "import xlrd\n",
    "import string\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download(\"wordnet\")\n",
    "import syllables\n",
    "from collections import Counter \n",
    "import os\n",
    "from bs4 import BeautifulSoup  \n",
    "from bs4.element import Comment\n",
    "import urllib.request\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0c6ec4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install spacy typing_extensions>=4.8.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f76cea37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kavit\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\thinc\\compat.py:36: UserWarning: 'has_mps' is deprecated, please use 'torch.backends.mps.is_built()'\n",
      "  hasattr(torch, \"has_mps\")\n",
      "C:\\Users\\kavit\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\thinc\\compat.py:37: UserWarning: 'has_mps' is deprecated, please use 'torch.backends.mps.is_built()'\n",
      "  and torch.has_mps  # type: ignore[attr-defined]\n"
     ]
    }
   ],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b210883",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def tag_visible(element):\n",
    "    if element.parent.name in ['style', 'script', 'head', 'title', 'meta', '[document]']:\n",
    "        return False\n",
    "    if isinstance(element, Comment):\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "\n",
    "def text_from_html(body):\n",
    "    soup = BeautifulSoup(body, 'html.parser')\n",
    "    title = soup.title(string = True)\n",
    "    texts = soup.findAll(string = True)\n",
    "    visible_texts = filter(tag_visible, texts) \n",
    "    return u\" \".join(t.strip() for t in visible_texts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c3c5644",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_df = pd.read_excel(\"E:\\Blackcoffer\\Output Data Structure.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c3fa4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = url_df['URL'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "993cb52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "html = urllib.request.urlopen(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "70c8b0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "htmlParse = BeautifulSoup(html, 'html.parser') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ad47669",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text(url, url_id):\n",
    "    html = urllib.request.urlopen(url).read()\n",
    "    text = text_from_html(html)\n",
    "    directory = \"E:\\Blackcoffer\\parsed_data\\\\\"\n",
    "    file_path  = directory + url_id + \".txt\"\n",
    "    text_file = open(file_path, \"w\", encoding=\"utf-8\")\n",
    "    text_file.write(text)\n",
    "    text_file.close()\n",
    "    \n",
    "    return\n",
    "\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f56eacaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i, url in enumerate(url_df['URL']):\n",
    "    #url_id = url_df.loc[i, 'URL_ID']\n",
    "    #extract_text(url, url_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "963b3918",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stop_words(text):\n",
    "    words = []\n",
    "    words = [word for word in text.split() if word.lower() not in sw_spacy]\n",
    "    new_text = \" \".join(words)\n",
    "    return new_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ed78d956",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(text):\n",
    "    punctuationfree=\"\".join([i for i in text if i not in '!\"#$%&\\'()*+,./:;<=>?@[\\\\]^_`{|}~'])\n",
    "    return punctuationfree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4584048e",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(r\"E:\\Blackcoffer\\parsed_data\\bctech2047.txt\", \"r\", encoding = 'utf-8')\n",
    "txt = f.readlines()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7b1cedbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = [x.strip().lower() for x in txt ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5e3896b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(text):\n",
    "    punctuationfree=\"\".join([i for i in text if i not in '|©!\"#$%&\\'()*+,./’:;<=>?@[\\\\]^_`{|}~'])\n",
    "    return punctuationfree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3338cc61",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "number_of_sentences = len(sent_tokenize(txt[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "54c76133",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_of_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4c2515cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = [remove_punctuation(x) for x in txt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c0272ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = [re.sub('[0-9]+', '', x) for x in txt]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "898edc47",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = [word_tokenize(x) for x in txt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cb127d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(r\"E:\\Blackcoffer\\sentiment\\positive-words.txt\", \"r\", encoding = 'utf-8')\n",
    "txt = f.readlines()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fea7609e",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_txt = [x.strip() for x in txt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c422292",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "05cea9de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a+', 'abound', 'abounds', 'abundance', 'abundant']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_txt [:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "123bb5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(r\"E:\\Blackcoffer\\sentiment\\negative-words.txt\", \"r\")\n",
    "negative_txt = f.readlines()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b03bf3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_txt = [x.strip() for x in negative_txt ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7405d6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3a47e6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(r\"E:\\Blackcoffer\\stopwords\\StopWords_Auditor.txt\", \"r\")\n",
    "stop_words = f.readlines()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2e3ce4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "files_sw = os.listdir(r'E:\\Blackcoffer\\stopwords\\\\')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "308ea7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = 'E:\\Blackcoffer\\stopwords\\\\'\n",
    "stopwords = []\n",
    "for file in files_sw:\n",
    "    file_path = directory + file\n",
    "    f = open(file_path, \"r\")\n",
    "    stop_words = f.readlines()\n",
    "    f.close()\n",
    "    stop_words = [x.strip().lower() for x in stop_words]\n",
    "    stop_words = [re.sub(r'http\\S+', '', x) for x in stop_words]\n",
    "    stop_words = [re.sub(r'www\\S+', '', x) for x in stop_words]\n",
    "    stop_words = [re.sub('|', '', x) for x in stop_words]\n",
    "    stop_words = [x.strip() for x in stop_words]\n",
    "    stop_words= [re.sub('[0-9]+', '', x) for x in stop_words]\n",
    "    stop_words = [remove_punctuation(x) for x in stop_words ]\n",
    "    stopwords.append(stop_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "52b3ac5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_l = []\n",
    "for txt_l in stopwords:\n",
    "    for j in txt_l:\n",
    "        if len(j.split(' ')) > 1:\n",
    "            j = j.split(' ')\n",
    "            j = [x for x in j if len(x) > 1]\n",
    "            for i in j:\n",
    "                stopwords_l.append(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c651d479",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['afghani', 'afghanistan', 'ariary', 'madagascar', 'baht']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords_l[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "56b6452d",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_count = Counter(stopwords_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5864709e",
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_counts = Counter(negative_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "244be300",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_counts = Counter(positive_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "39fdf99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_txt_file(file):\n",
    "    sen = 0\n",
    "    word_count = 0\n",
    "    pro_count = 0\n",
    "    f = open(file, \"r\", encoding = 'utf-8')\n",
    "    txt = f.readlines()\n",
    "    f.close()\n",
    "    pronounRegex = re.compile(r'\\b(I|we|my|our|ours|you|your|yours|they|them|(?-i:us))\\b',re.I)\n",
    "    pronouns = len(pronounRegex.findall(\" \".join(txt)))\n",
    "    sen = len(sent_tokenize(txt[0]))\n",
    "    txt = [x.strip().lower() for x in txt ]\n",
    "    txt = [remove_punctuation(x) for x in txt]\n",
    "    txt = [re.sub('[0-9]+', '', x) for x in txt]\n",
    "    txt = [word_tokenize(x) for x in txt]\n",
    "    txt = [lemmatiser.lemmatize(x) for x in txt[0] if x not in sw_spacy and x not in stopwords_count.keys()]\n",
    "\n",
    "    word_count += len(txt)\n",
    "    return sen, word_count, pronouns, txt\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3fc37b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatiser = WordNetLemmatizer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3d37b1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "#loading the english language small model of spacy\n",
    "en = spacy.load('en_core_web_sm')\n",
    "sw_spacy = en.Defaults.stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bfa17214",
   "metadata": {},
   "outputs": [],
   "source": [
    "sen, wc , pro_count, word_l = read_txt_file(r\"E:\\Blackcoffer\\parsed_data\\bctech2011.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "305c8525",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sign', 'success', 'story', 'banking', 'financials']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_l[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "588da1c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pro_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "de5f8299",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2495"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8dff553b",
   "metadata": {},
   "outputs": [],
   "source": [
    " import syllables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a7aa4ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_feature(file_path, positive_counts, negative_counts):\n",
    "    sen = 0\n",
    "    wc = 0\n",
    "    pro_count = 0\n",
    "    pos = 0\n",
    "    neg = 0\n",
    "    cw = 0\n",
    "    tcw = 0\n",
    "    char_count = 0\n",
    "    sen, wc, pro_count, word_l =  read_txt_file(file_path)\n",
    "    pos_neg_count = []\n",
    "    for word in word_l:\n",
    "        neg += negative_counts.get(word, 0)\n",
    "        pos += positive_counts.get(word, 0) \n",
    "        char_count += len(word)\n",
    "        if syllables.estimate(word) > 2:\n",
    "            cw += 1\n",
    "        tcw += syllables.estimate(word)\n",
    "    polarity_score = np.round((pos - neg)/ ((pos + neg) + 0.000001),4)\n",
    "    subjectivity_score = np.round((pos + neg)/ ((len(word_l)) + 0.000001),4)\n",
    "    avg_sentence_len = np.round(wc/sen,4)\n",
    "    perce_cw = np.round(cw/wc * 100, 4) \n",
    "    fog = np.round(0.4 * (avg_sentence_len + perce_cw),4)\n",
    "    avg_words_per_sen = np.round(wc/sen,4)\n",
    "    syl_per_word = np.round(tcw/wc,4)\n",
    "    avg_word_length = np.round(char_count/wc, 4)\n",
    "    pos_neg_count.append([pos, neg, polarity_score, subjectivity_score,avg_sentence_len, perce_cw, fog, avg_words_per_sen, cw, wc, syl_per_word, pro_count, avg_word_length ])\n",
    "    return pos_neg_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a7f24995",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[64,\n",
       "  10,\n",
       "  0.7297,\n",
       "  0.0754,\n",
       "  51.6316,\n",
       "  45.2599,\n",
       "  38.7566,\n",
       "  51.6316,\n",
       "  444,\n",
       "  981,\n",
       "  2.5178,\n",
       "  53,\n",
       "  7.0754]]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_feature('E:\\Blackcoffer\\parsed_data\\\\bctech2047.txt',  positive_counts, negative_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "27378ff1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'a+': 1,\n",
       "         'abound': 1,\n",
       "         'abounds': 1,\n",
       "         'abundance': 1,\n",
       "         'abundant': 1,\n",
       "         'accessable': 1,\n",
       "         'accessible': 1,\n",
       "         'acclaim': 1,\n",
       "         'acclaimed': 1,\n",
       "         'acclamation': 1,\n",
       "         'accolade': 1,\n",
       "         'accolades': 1,\n",
       "         'accommodative': 1,\n",
       "         'accomodative': 1,\n",
       "         'accomplish': 1,\n",
       "         'accomplished': 1,\n",
       "         'accomplishment': 1,\n",
       "         'accomplishments': 1,\n",
       "         'accurate': 1,\n",
       "         'accurately': 1,\n",
       "         'achievable': 1,\n",
       "         'achievement': 1,\n",
       "         'achievements': 1,\n",
       "         'achievible': 1,\n",
       "         'acumen': 1,\n",
       "         'adaptable': 1,\n",
       "         'adaptive': 1,\n",
       "         'adequate': 1,\n",
       "         'adjustable': 1,\n",
       "         'admirable': 1,\n",
       "         'admirably': 1,\n",
       "         'admiration': 1,\n",
       "         'admire': 1,\n",
       "         'admirer': 1,\n",
       "         'admiring': 1,\n",
       "         'admiringly': 1,\n",
       "         'adorable': 1,\n",
       "         'adore': 1,\n",
       "         'adored': 1,\n",
       "         'adorer': 1,\n",
       "         'adoring': 1,\n",
       "         'adoringly': 1,\n",
       "         'adroit': 1,\n",
       "         'adroitly': 1,\n",
       "         'adulate': 1,\n",
       "         'adulation': 1,\n",
       "         'adulatory': 1,\n",
       "         'advanced': 1,\n",
       "         'advantage': 1,\n",
       "         'advantageous': 1,\n",
       "         'advantageously': 1,\n",
       "         'advantages': 1,\n",
       "         'adventuresome': 1,\n",
       "         'adventurous': 1,\n",
       "         'advocate': 1,\n",
       "         'advocated': 1,\n",
       "         'advocates': 1,\n",
       "         'affability': 1,\n",
       "         'affable': 1,\n",
       "         'affably': 1,\n",
       "         'affectation': 1,\n",
       "         'affection': 1,\n",
       "         'affectionate': 1,\n",
       "         'affinity': 1,\n",
       "         'affirm': 1,\n",
       "         'affirmation': 1,\n",
       "         'affirmative': 1,\n",
       "         'affluence': 1,\n",
       "         'affluent': 1,\n",
       "         'afford': 1,\n",
       "         'affordable': 1,\n",
       "         'affordably': 1,\n",
       "         'afordable': 1,\n",
       "         'agile': 1,\n",
       "         'agilely': 1,\n",
       "         'agility': 1,\n",
       "         'agreeable': 1,\n",
       "         'agreeableness': 1,\n",
       "         'agreeably': 1,\n",
       "         'all-around': 1,\n",
       "         'alluring': 1,\n",
       "         'alluringly': 1,\n",
       "         'altruistic': 1,\n",
       "         'altruistically': 1,\n",
       "         'amaze': 1,\n",
       "         'amazed': 1,\n",
       "         'amazement': 1,\n",
       "         'amazes': 1,\n",
       "         'amazing': 1,\n",
       "         'amazingly': 1,\n",
       "         'ambitious': 1,\n",
       "         'ambitiously': 1,\n",
       "         'ameliorate': 1,\n",
       "         'amenable': 1,\n",
       "         'amenity': 1,\n",
       "         'amiability': 1,\n",
       "         'amiabily': 1,\n",
       "         'amiable': 1,\n",
       "         'amicability': 1,\n",
       "         'amicable': 1,\n",
       "         'amicably': 1,\n",
       "         'amity': 1,\n",
       "         'ample': 1,\n",
       "         'amply': 1,\n",
       "         'amuse': 1,\n",
       "         'amusing': 1,\n",
       "         'amusingly': 1,\n",
       "         'angel': 1,\n",
       "         'angelic': 1,\n",
       "         'apotheosis': 1,\n",
       "         'appeal': 1,\n",
       "         'appealing': 1,\n",
       "         'applaud': 1,\n",
       "         'appreciable': 1,\n",
       "         'appreciate': 1,\n",
       "         'appreciated': 1,\n",
       "         'appreciates': 1,\n",
       "         'appreciative': 1,\n",
       "         'appreciatively': 1,\n",
       "         'appropriate': 1,\n",
       "         'approval': 1,\n",
       "         'approve': 1,\n",
       "         'ardent': 1,\n",
       "         'ardently': 1,\n",
       "         'ardor': 1,\n",
       "         'articulate': 1,\n",
       "         'aspiration': 1,\n",
       "         'aspirations': 1,\n",
       "         'aspire': 1,\n",
       "         'assurance': 1,\n",
       "         'assurances': 1,\n",
       "         'assure': 1,\n",
       "         'assuredly': 1,\n",
       "         'assuring': 1,\n",
       "         'astonish': 1,\n",
       "         'astonished': 1,\n",
       "         'astonishing': 1,\n",
       "         'astonishingly': 1,\n",
       "         'astonishment': 1,\n",
       "         'astound': 1,\n",
       "         'astounded': 1,\n",
       "         'astounding': 1,\n",
       "         'astoundingly': 1,\n",
       "         'astutely': 1,\n",
       "         'attentive': 1,\n",
       "         'attraction': 1,\n",
       "         'attractive': 1,\n",
       "         'attractively': 1,\n",
       "         'attune': 1,\n",
       "         'audible': 1,\n",
       "         'audibly': 1,\n",
       "         'auspicious': 1,\n",
       "         'authentic': 1,\n",
       "         'authoritative': 1,\n",
       "         'autonomous': 1,\n",
       "         'available': 1,\n",
       "         'aver': 1,\n",
       "         'avid': 1,\n",
       "         'avidly': 1,\n",
       "         'award': 1,\n",
       "         'awarded': 1,\n",
       "         'awards': 1,\n",
       "         'awe': 1,\n",
       "         'awed': 1,\n",
       "         'awesome': 1,\n",
       "         'awesomely': 1,\n",
       "         'awesomeness': 1,\n",
       "         'awestruck': 1,\n",
       "         'awsome': 1,\n",
       "         'backbone': 1,\n",
       "         'balanced': 1,\n",
       "         'bargain': 1,\n",
       "         'beauteous': 1,\n",
       "         'beautiful': 1,\n",
       "         'beautifullly': 1,\n",
       "         'beautifully': 1,\n",
       "         'beautify': 1,\n",
       "         'beauty': 1,\n",
       "         'beckon': 1,\n",
       "         'beckoned': 1,\n",
       "         'beckoning': 1,\n",
       "         'beckons': 1,\n",
       "         'believable': 1,\n",
       "         'believeable': 1,\n",
       "         'beloved': 1,\n",
       "         'benefactor': 1,\n",
       "         'beneficent': 1,\n",
       "         'beneficial': 1,\n",
       "         'beneficially': 1,\n",
       "         'beneficiary': 1,\n",
       "         'benefit': 1,\n",
       "         'benefits': 1,\n",
       "         'benevolence': 1,\n",
       "         'benevolent': 1,\n",
       "         'benifits': 1,\n",
       "         'best': 1,\n",
       "         'best-known': 1,\n",
       "         'best-performing': 1,\n",
       "         'best-selling': 1,\n",
       "         'better': 1,\n",
       "         'better-known': 1,\n",
       "         'better-than-expected': 1,\n",
       "         'beutifully': 1,\n",
       "         'blameless': 1,\n",
       "         'bless': 1,\n",
       "         'blessing': 1,\n",
       "         'bliss': 1,\n",
       "         'blissful': 1,\n",
       "         'blissfully': 1,\n",
       "         'blithe': 1,\n",
       "         'blockbuster': 1,\n",
       "         'bloom': 1,\n",
       "         'blossom': 1,\n",
       "         'bolster': 1,\n",
       "         'bonny': 1,\n",
       "         'bonus': 1,\n",
       "         'bonuses': 1,\n",
       "         'boom': 1,\n",
       "         'booming': 1,\n",
       "         'boost': 1,\n",
       "         'boundless': 1,\n",
       "         'bountiful': 1,\n",
       "         'brainiest': 1,\n",
       "         'brainy': 1,\n",
       "         'brand-new': 1,\n",
       "         'brave': 1,\n",
       "         'bravery': 1,\n",
       "         'bravo': 1,\n",
       "         'breakthrough': 1,\n",
       "         'breakthroughs': 1,\n",
       "         'breathlessness': 1,\n",
       "         'breathtaking': 1,\n",
       "         'breathtakingly': 1,\n",
       "         'breeze': 1,\n",
       "         'bright': 1,\n",
       "         'brighten': 1,\n",
       "         'brighter': 1,\n",
       "         'brightest': 1,\n",
       "         'brilliance': 1,\n",
       "         'brilliances': 1,\n",
       "         'brilliant': 1,\n",
       "         'brilliantly': 1,\n",
       "         'brisk': 1,\n",
       "         'brotherly': 1,\n",
       "         'bullish': 1,\n",
       "         'buoyant': 1,\n",
       "         'cajole': 1,\n",
       "         'calm': 1,\n",
       "         'calming': 1,\n",
       "         'calmness': 1,\n",
       "         'capability': 1,\n",
       "         'capable': 1,\n",
       "         'capably': 1,\n",
       "         'captivate': 1,\n",
       "         'captivating': 1,\n",
       "         'carefree': 1,\n",
       "         'cashback': 1,\n",
       "         'cashbacks': 1,\n",
       "         'catchy': 1,\n",
       "         'celebrate': 1,\n",
       "         'celebrated': 1,\n",
       "         'celebration': 1,\n",
       "         'celebratory': 1,\n",
       "         'champ': 1,\n",
       "         'champion': 1,\n",
       "         'charisma': 1,\n",
       "         'charismatic': 1,\n",
       "         'charitable': 1,\n",
       "         'charm': 1,\n",
       "         'charming': 1,\n",
       "         'charmingly': 1,\n",
       "         'chaste': 1,\n",
       "         'cheaper': 1,\n",
       "         'cheapest': 1,\n",
       "         'cheer': 1,\n",
       "         'cheerful': 1,\n",
       "         'cheery': 1,\n",
       "         'cherish': 1,\n",
       "         'cherished': 1,\n",
       "         'cherub': 1,\n",
       "         'chic': 1,\n",
       "         'chivalrous': 1,\n",
       "         'chivalry': 1,\n",
       "         'civility': 1,\n",
       "         'civilize': 1,\n",
       "         'clarity': 1,\n",
       "         'classic': 1,\n",
       "         'classy': 1,\n",
       "         'clean': 1,\n",
       "         'cleaner': 1,\n",
       "         'cleanest': 1,\n",
       "         'cleanliness': 1,\n",
       "         'cleanly': 1,\n",
       "         'clear': 1,\n",
       "         'clear-cut': 1,\n",
       "         'cleared': 1,\n",
       "         'clearer': 1,\n",
       "         'clearly': 1,\n",
       "         'clears': 1,\n",
       "         'clever': 1,\n",
       "         'cleverly': 1,\n",
       "         'cohere': 1,\n",
       "         'coherence': 1,\n",
       "         'coherent': 1,\n",
       "         'cohesive': 1,\n",
       "         'colorful': 1,\n",
       "         'comely': 1,\n",
       "         'comfort': 1,\n",
       "         'comfortable': 1,\n",
       "         'comfortably': 1,\n",
       "         'comforting': 1,\n",
       "         'comfy': 1,\n",
       "         'commend': 1,\n",
       "         'commendable': 1,\n",
       "         'commendably': 1,\n",
       "         'commitment': 1,\n",
       "         'commodious': 1,\n",
       "         'compact': 1,\n",
       "         'compactly': 1,\n",
       "         'compassion': 1,\n",
       "         'compassionate': 1,\n",
       "         'compatible': 1,\n",
       "         'competitive': 1,\n",
       "         'complement': 1,\n",
       "         'complementary': 1,\n",
       "         'complemented': 1,\n",
       "         'complements': 1,\n",
       "         'compliant': 1,\n",
       "         'compliment': 1,\n",
       "         'complimentary': 1,\n",
       "         'comprehensive': 1,\n",
       "         'conciliate': 1,\n",
       "         'conciliatory': 1,\n",
       "         'concise': 1,\n",
       "         'confidence': 1,\n",
       "         'confident': 1,\n",
       "         'congenial': 1,\n",
       "         'congratulate': 1,\n",
       "         'congratulation': 1,\n",
       "         'congratulations': 1,\n",
       "         'congratulatory': 1,\n",
       "         'conscientious': 1,\n",
       "         'considerate': 1,\n",
       "         'consistent': 1,\n",
       "         'consistently': 1,\n",
       "         'constructive': 1,\n",
       "         'consummate': 1,\n",
       "         'contentment': 1,\n",
       "         'continuity': 1,\n",
       "         'contrasty': 1,\n",
       "         'contribution': 1,\n",
       "         'convenience': 1,\n",
       "         'convenient': 1,\n",
       "         'conveniently': 1,\n",
       "         'convience': 1,\n",
       "         'convienient': 1,\n",
       "         'convient': 1,\n",
       "         'convincing': 1,\n",
       "         'convincingly': 1,\n",
       "         'cool': 1,\n",
       "         'coolest': 1,\n",
       "         'cooperative': 1,\n",
       "         'cooperatively': 1,\n",
       "         'cornerstone': 1,\n",
       "         'correct': 1,\n",
       "         'correctly': 1,\n",
       "         'cost-effective': 1,\n",
       "         'cost-saving': 1,\n",
       "         'counter-attack': 1,\n",
       "         'counter-attacks': 1,\n",
       "         'courage': 1,\n",
       "         'courageous': 1,\n",
       "         'courageously': 1,\n",
       "         'courageousness': 1,\n",
       "         'courteous': 1,\n",
       "         'courtly': 1,\n",
       "         'covenant': 1,\n",
       "         'cozy': 1,\n",
       "         'creative': 1,\n",
       "         'credence': 1,\n",
       "         'credible': 1,\n",
       "         'crisp': 1,\n",
       "         'crisper': 1,\n",
       "         'cure': 1,\n",
       "         'cure-all': 1,\n",
       "         'cushy': 1,\n",
       "         'cute': 1,\n",
       "         'cuteness': 1,\n",
       "         'danke': 1,\n",
       "         'danken': 1,\n",
       "         'daring': 1,\n",
       "         'daringly': 1,\n",
       "         'darling': 1,\n",
       "         'dashing': 1,\n",
       "         'dauntless': 1,\n",
       "         'dawn': 1,\n",
       "         'dazzle': 1,\n",
       "         'dazzled': 1,\n",
       "         'dazzling': 1,\n",
       "         'dead-cheap': 1,\n",
       "         'dead-on': 1,\n",
       "         'decency': 1,\n",
       "         'decent': 1,\n",
       "         'decisive': 1,\n",
       "         'decisiveness': 1,\n",
       "         'dedicated': 1,\n",
       "         'defeat': 1,\n",
       "         'defeated': 1,\n",
       "         'defeating': 1,\n",
       "         'defeats': 1,\n",
       "         'defender': 1,\n",
       "         'deference': 1,\n",
       "         'deft': 1,\n",
       "         'deginified': 1,\n",
       "         'delectable': 1,\n",
       "         'delicacy': 1,\n",
       "         'delicate': 1,\n",
       "         'delicious': 1,\n",
       "         'delight': 1,\n",
       "         'delighted': 1,\n",
       "         'delightful': 1,\n",
       "         'delightfully': 1,\n",
       "         'delightfulness': 1,\n",
       "         'dependable': 1,\n",
       "         'dependably': 1,\n",
       "         'deservedly': 1,\n",
       "         'deserving': 1,\n",
       "         'desirable': 1,\n",
       "         'desiring': 1,\n",
       "         'desirous': 1,\n",
       "         'destiny': 1,\n",
       "         'detachable': 1,\n",
       "         'devout': 1,\n",
       "         'dexterous': 1,\n",
       "         'dexterously': 1,\n",
       "         'dextrous': 1,\n",
       "         'dignified': 1,\n",
       "         'dignify': 1,\n",
       "         'dignity': 1,\n",
       "         'diligence': 1,\n",
       "         'diligent': 1,\n",
       "         'diligently': 1,\n",
       "         'diplomatic': 1,\n",
       "         'dirt-cheap': 1,\n",
       "         'distinction': 1,\n",
       "         'distinctive': 1,\n",
       "         'distinguished': 1,\n",
       "         'diversified': 1,\n",
       "         'divine': 1,\n",
       "         'divinely': 1,\n",
       "         'dominate': 1,\n",
       "         'dominated': 1,\n",
       "         'dominates': 1,\n",
       "         'dote': 1,\n",
       "         'dotingly': 1,\n",
       "         'doubtless': 1,\n",
       "         'dreamland': 1,\n",
       "         'dumbfounded': 1,\n",
       "         'dumbfounding': 1,\n",
       "         'dummy-proof': 1,\n",
       "         'durable': 1,\n",
       "         'dynamic': 1,\n",
       "         'eager': 1,\n",
       "         'eagerly': 1,\n",
       "         'eagerness': 1,\n",
       "         'earnest': 1,\n",
       "         'earnestly': 1,\n",
       "         'earnestness': 1,\n",
       "         'ease': 1,\n",
       "         'eased': 1,\n",
       "         'eases': 1,\n",
       "         'easier': 1,\n",
       "         'easiest': 1,\n",
       "         'easiness': 1,\n",
       "         'easing': 1,\n",
       "         'easy': 1,\n",
       "         'easy-to-use': 1,\n",
       "         'easygoing': 1,\n",
       "         'ebullience': 1,\n",
       "         'ebullient': 1,\n",
       "         'ebulliently': 1,\n",
       "         'ecenomical': 1,\n",
       "         'economical': 1,\n",
       "         'ecstasies': 1,\n",
       "         'ecstasy': 1,\n",
       "         'ecstatic': 1,\n",
       "         'ecstatically': 1,\n",
       "         'edify': 1,\n",
       "         'educated': 1,\n",
       "         'effective': 1,\n",
       "         'effectively': 1,\n",
       "         'effectiveness': 1,\n",
       "         'effectual': 1,\n",
       "         'efficacious': 1,\n",
       "         'efficient': 1,\n",
       "         'efficiently': 1,\n",
       "         'effortless': 1,\n",
       "         'effortlessly': 1,\n",
       "         'effusion': 1,\n",
       "         'effusive': 1,\n",
       "         'effusively': 1,\n",
       "         'effusiveness': 1,\n",
       "         'elan': 1,\n",
       "         'elate': 1,\n",
       "         'elated': 1,\n",
       "         'elatedly': 1,\n",
       "         'elation': 1,\n",
       "         'electrify': 1,\n",
       "         'elegance': 1,\n",
       "         'elegant': 1,\n",
       "         'elegantly': 1,\n",
       "         'elevate': 1,\n",
       "         'elite': 1,\n",
       "         'eloquence': 1,\n",
       "         'eloquent': 1,\n",
       "         'eloquently': 1,\n",
       "         'embolden': 1,\n",
       "         'eminence': 1,\n",
       "         'eminent': 1,\n",
       "         'empathize': 1,\n",
       "         'empathy': 1,\n",
       "         'empower': 1,\n",
       "         'empowerment': 1,\n",
       "         'enchant': 1,\n",
       "         'enchanted': 1,\n",
       "         'enchanting': 1,\n",
       "         'enchantingly': 1,\n",
       "         'encourage': 1,\n",
       "         'encouragement': 1,\n",
       "         'encouraging': 1,\n",
       "         'encouragingly': 1,\n",
       "         'endear': 1,\n",
       "         'endearing': 1,\n",
       "         'endorse': 1,\n",
       "         'endorsed': 1,\n",
       "         'endorsement': 1,\n",
       "         'endorses': 1,\n",
       "         'endorsing': 1,\n",
       "         'energetic': 1,\n",
       "         'energize': 1,\n",
       "         'energy-efficient': 1,\n",
       "         'energy-saving': 1,\n",
       "         'engaging': 1,\n",
       "         'engrossing': 1,\n",
       "         'enhance': 1,\n",
       "         'enhanced': 1,\n",
       "         'enhancement': 1,\n",
       "         'enhances': 1,\n",
       "         'enjoy': 1,\n",
       "         'enjoyable': 1,\n",
       "         'enjoyably': 1,\n",
       "         'enjoyed': 1,\n",
       "         'enjoying': 1,\n",
       "         'enjoyment': 1,\n",
       "         'enjoys': 1,\n",
       "         'enlighten': 1,\n",
       "         'enlightenment': 1,\n",
       "         'enliven': 1,\n",
       "         'ennoble': 1,\n",
       "         'enough': 1,\n",
       "         'enrapt': 1,\n",
       "         'enrapture': 1,\n",
       "         'enraptured': 1,\n",
       "         'enrich': 1,\n",
       "         'enrichment': 1,\n",
       "         'enterprising': 1,\n",
       "         'entertain': 1,\n",
       "         'entertaining': 1,\n",
       "         'entertains': 1,\n",
       "         'enthral': 1,\n",
       "         'enthrall': 1,\n",
       "         'enthralled': 1,\n",
       "         'enthuse': 1,\n",
       "         'enthusiasm': 1,\n",
       "         'enthusiast': 1,\n",
       "         'enthusiastic': 1,\n",
       "         'enthusiastically': 1,\n",
       "         'entice': 1,\n",
       "         'enticed': 1,\n",
       "         'enticing': 1,\n",
       "         'enticingly': 1,\n",
       "         'entranced': 1,\n",
       "         'entrancing': 1,\n",
       "         'entrust': 1,\n",
       "         'enviable': 1,\n",
       "         'enviably': 1,\n",
       "         'envious': 1,\n",
       "         'enviously': 1,\n",
       "         'enviousness': 1,\n",
       "         'envy': 1,\n",
       "         'equitable': 1,\n",
       "         'ergonomical': 1,\n",
       "         'err-free': 1,\n",
       "         'erudite': 1,\n",
       "         'ethical': 1,\n",
       "         'eulogize': 1,\n",
       "         'euphoria': 1,\n",
       "         'euphoric': 1,\n",
       "         'euphorically': 1,\n",
       "         'evaluative': 1,\n",
       "         'evenly': 1,\n",
       "         'eventful': 1,\n",
       "         'everlasting': 1,\n",
       "         'evocative': 1,\n",
       "         'exalt': 1,\n",
       "         'exaltation': 1,\n",
       "         'exalted': 1,\n",
       "         'exaltedly': 1,\n",
       "         'exalting': 1,\n",
       "         'exaltingly': 1,\n",
       "         'examplar': 1,\n",
       "         'examplary': 1,\n",
       "         'excallent': 1,\n",
       "         'exceed': 1,\n",
       "         'exceeded': 1,\n",
       "         'exceeding': 1,\n",
       "         'exceedingly': 1,\n",
       "         'exceeds': 1,\n",
       "         'excel': 1,\n",
       "         'exceled': 1,\n",
       "         'excelent': 1,\n",
       "         'excellant': 1,\n",
       "         'excelled': 1,\n",
       "         'excellence': 1,\n",
       "         'excellency': 1,\n",
       "         'excellent': 1,\n",
       "         'excellently': 1,\n",
       "         'excels': 1,\n",
       "         'exceptional': 1,\n",
       "         'exceptionally': 1,\n",
       "         'excite': 1,\n",
       "         'excited': 1,\n",
       "         'excitedly': 1,\n",
       "         'excitedness': 1,\n",
       "         'excitement': 1,\n",
       "         'excites': 1,\n",
       "         'exciting': 1,\n",
       "         'excitingly': 1,\n",
       "         'exellent': 1,\n",
       "         'exemplar': 1,\n",
       "         'exemplary': 1,\n",
       "         'exhilarate': 1,\n",
       "         'exhilarating': 1,\n",
       "         'exhilaratingly': 1,\n",
       "         'exhilaration': 1,\n",
       "         'exonerate': 1,\n",
       "         'expansive': 1,\n",
       "         'expeditiously': 1,\n",
       "         'expertly': 1,\n",
       "         'exquisite': 1,\n",
       "         'exquisitely': 1,\n",
       "         'extol': 1,\n",
       "         'extoll': 1,\n",
       "         'extraordinarily': 1,\n",
       "         'extraordinary': 1,\n",
       "         'exuberance': 1,\n",
       "         'exuberant': 1,\n",
       "         'exuberantly': 1,\n",
       "         'exult': 1,\n",
       "         'exultant': 1,\n",
       "         'exultation': 1,\n",
       "         'exultingly': 1,\n",
       "         'eye-catch': 1,\n",
       "         'eye-catching': 1,\n",
       "         'eyecatch': 1,\n",
       "         'eyecatching': 1,\n",
       "         'fabulous': 1,\n",
       "         'fabulously': 1,\n",
       "         'facilitate': 1,\n",
       "         'fair': 1,\n",
       "         'fairly': 1,\n",
       "         'fairness': 1,\n",
       "         'faith': 1,\n",
       "         'faithful': 1,\n",
       "         'faithfully': 1,\n",
       "         'faithfulness': 1,\n",
       "         'fame': 1,\n",
       "         'famed': 1,\n",
       "         'famous': 1,\n",
       "         'famously': 1,\n",
       "         'fancier': 1,\n",
       "         'fancinating': 1,\n",
       "         'fancy': 1,\n",
       "         'fanfare': 1,\n",
       "         'fans': 1,\n",
       "         'fantastic': 1,\n",
       "         'fantastically': 1,\n",
       "         'fascinate': 1,\n",
       "         'fascinating': 1,\n",
       "         'fascinatingly': 1,\n",
       "         'fascination': 1,\n",
       "         'fashionable': 1,\n",
       "         'fashionably': 1,\n",
       "         'fast': 1,\n",
       "         'fast-growing': 1,\n",
       "         'fast-paced': 1,\n",
       "         'faster': 1,\n",
       "         'fastest': 1,\n",
       "         'fastest-growing': 1,\n",
       "         'faultless': 1,\n",
       "         'fav': 1,\n",
       "         'fave': 1,\n",
       "         'favor': 1,\n",
       "         'favorable': 1,\n",
       "         'favored': 1,\n",
       "         'favorite': 1,\n",
       "         'favorited': 1,\n",
       "         'favour': 1,\n",
       "         'fearless': 1,\n",
       "         'fearlessly': 1,\n",
       "         'feasible': 1,\n",
       "         'feasibly': 1,\n",
       "         'feat': 1,\n",
       "         'feature-rich': 1,\n",
       "         'fecilitous': 1,\n",
       "         'feisty': 1,\n",
       "         'felicitate': 1,\n",
       "         'felicitous': 1,\n",
       "         'felicity': 1,\n",
       "         'fertile': 1,\n",
       "         'fervent': 1,\n",
       "         'fervently': 1,\n",
       "         'fervid': 1,\n",
       "         'fervidly': 1,\n",
       "         'fervor': 1,\n",
       "         'festive': 1,\n",
       "         'fidelity': 1,\n",
       "         'fiery': 1,\n",
       "         'fine': 1,\n",
       "         'fine-looking': 1,\n",
       "         'finely': 1,\n",
       "         'finer': 1,\n",
       "         'finest': 1,\n",
       "         'firmer': 1,\n",
       "         'first-class': 1,\n",
       "         'first-in-class': 1,\n",
       "         'first-rate': 1,\n",
       "         'flashy': 1,\n",
       "         'flatter': 1,\n",
       "         'flattering': 1,\n",
       "         'flatteringly': 1,\n",
       "         'flawless': 1,\n",
       "         'flawlessly': 1,\n",
       "         'flexibility': 1,\n",
       "         'flexible': 1,\n",
       "         'flourish': 1,\n",
       "         'flourishing': 1,\n",
       "         'fluent': 1,\n",
       "         'flutter': 1,\n",
       "         'fond': 1,\n",
       "         'fondly': 1,\n",
       "         'fondness': 1,\n",
       "         'foolproof': 1,\n",
       "         'foremost': 1,\n",
       "         'foresight': 1,\n",
       "         'formidable': 1,\n",
       "         'fortitude': 1,\n",
       "         'fortuitous': 1,\n",
       "         'fortuitously': 1,\n",
       "         'fortunate': 1,\n",
       "         'fortunately': 1,\n",
       "         'fortune': 1,\n",
       "         'fragrant': 1,\n",
       "         'free': 1,\n",
       "         'freed': 1,\n",
       "         'freedom': 1,\n",
       "         'freedoms': 1,\n",
       "         'fresh': 1,\n",
       "         'fresher': 1,\n",
       "         'freshest': 1,\n",
       "         'friendliness': 1,\n",
       "         'friendly': 1,\n",
       "         'frolic': 1,\n",
       "         'frugal': 1,\n",
       "         'fruitful': 1,\n",
       "         'ftw': 1,\n",
       "         'fulfillment': 1,\n",
       "         'fun': 1,\n",
       "         'futurestic': 1,\n",
       "         'futuristic': 1,\n",
       "         'gaiety': 1,\n",
       "         'gaily': 1,\n",
       "         'gain': 1,\n",
       "         'gained': 1,\n",
       "         'gainful': 1,\n",
       "         'gainfully': 1,\n",
       "         'gaining': 1,\n",
       "         'gains': 1,\n",
       "         'gallant': 1,\n",
       "         'gallantly': 1,\n",
       "         'galore': 1,\n",
       "         'geekier': 1,\n",
       "         'geeky': 1,\n",
       "         'gem': 1,\n",
       "         'gems': 1,\n",
       "         'generosity': 1,\n",
       "         'generous': 1,\n",
       "         'generously': 1,\n",
       "         'genial': 1,\n",
       "         'genius': 1,\n",
       "         'gentle': 1,\n",
       "         'gentlest': 1,\n",
       "         'genuine': 1,\n",
       "         'gifted': 1,\n",
       "         'glad': 1,\n",
       "         'gladden': 1,\n",
       "         'gladly': 1,\n",
       "         'gladness': 1,\n",
       "         'glamorous': 1,\n",
       "         'glee': 1,\n",
       "         'gleeful': 1,\n",
       "         'gleefully': 1,\n",
       "         'glimmer': 1,\n",
       "         'glimmering': 1,\n",
       "         'glisten': 1,\n",
       "         'glistening': 1,\n",
       "         'glitter': 1,\n",
       "         'glitz': 1,\n",
       "         'glorify': 1,\n",
       "         'glorious': 1,\n",
       "         'gloriously': 1,\n",
       "         'glory': 1,\n",
       "         'glow': 1,\n",
       "         'glowing': 1,\n",
       "         'glowingly': 1,\n",
       "         'god-given': 1,\n",
       "         'god-send': 1,\n",
       "         'godlike': 1,\n",
       "         'godsend': 1,\n",
       "         'gold': 1,\n",
       "         'golden': 1,\n",
       "         'good': 1,\n",
       "         'goodly': 1,\n",
       "         'goodness': 1,\n",
       "         'goodwill': 1,\n",
       "         'goood': 1,\n",
       "         'gooood': 1,\n",
       "         'gorgeous': 1,\n",
       "         'gorgeously': 1,\n",
       "         'grace': 1,\n",
       "         'graceful': 1,\n",
       "         'gracefully': 1,\n",
       "         'gracious': 1,\n",
       "         'graciously': 1,\n",
       "         'graciousness': 1,\n",
       "         'grand': 1,\n",
       "         'grandeur': 1,\n",
       "         'grateful': 1,\n",
       "         'gratefully': 1,\n",
       "         'gratification': 1,\n",
       "         'gratified': 1,\n",
       "         'gratifies': 1,\n",
       "         'gratify': 1,\n",
       "         'gratifying': 1,\n",
       "         'gratifyingly': 1,\n",
       "         'gratitude': 1,\n",
       "         'great': 1,\n",
       "         'greatest': 1,\n",
       "         'greatness': 1,\n",
       "         'grin': 1,\n",
       "         'groundbreaking': 1,\n",
       "         'guarantee': 1,\n",
       "         'guidance': 1,\n",
       "         'guiltless': 1,\n",
       "         'gumption': 1,\n",
       "         'gush': 1,\n",
       "         'gusto': 1,\n",
       "         'gutsy': 1,\n",
       "         'hail': 1,\n",
       "         'halcyon': 1,\n",
       "         'hale': 1,\n",
       "         'hallmark': 1,\n",
       "         'hallmarks': 1,\n",
       "         'hallowed': 1,\n",
       "         'handier': 1,\n",
       "         'handily': 1,\n",
       "         'hands-down': 1,\n",
       "         'handsome': 1,\n",
       "         'handsomely': 1,\n",
       "         'handy': 1,\n",
       "         'happier': 1,\n",
       "         'happily': 1,\n",
       "         'happiness': 1,\n",
       "         'happy': 1,\n",
       "         'hard-working': 1,\n",
       "         'hardier': 1,\n",
       "         'hardy': 1,\n",
       "         'harmless': 1,\n",
       "         'harmonious': 1,\n",
       "         'harmoniously': 1,\n",
       "         'harmonize': 1,\n",
       "         'harmony': 1,\n",
       "         'headway': 1,\n",
       "         'heal': 1,\n",
       "         'healthful': 1,\n",
       "         'healthy': 1,\n",
       "         'hearten': 1,\n",
       "         'heartening': 1,\n",
       "         'heartfelt': 1,\n",
       "         'heartily': 1,\n",
       "         'heartwarming': 1,\n",
       "         'heaven': 1,\n",
       "         'heavenly': 1,\n",
       "         'helped': 1,\n",
       "         'helpful': 1,\n",
       "         'helping': 1,\n",
       "         'hero': 1,\n",
       "         'heroic': 1,\n",
       "         'heroically': 1,\n",
       "         'heroine': 1,\n",
       "         'heroize': 1,\n",
       "         'heros': 1,\n",
       "         'high-quality': 1,\n",
       "         'high-spirited': 1,\n",
       "         'hilarious': 1,\n",
       "         'holy': 1,\n",
       "         'homage': 1,\n",
       "         'honest': 1,\n",
       "         'honesty': 1,\n",
       "         'honor': 1,\n",
       "         'honorable': 1,\n",
       "         'honored': 1,\n",
       "         'honoring': 1,\n",
       "         'hooray': 1,\n",
       "         'hopeful': 1,\n",
       "         'hospitable': 1,\n",
       "         'hot': 1,\n",
       "         'hotcake': 1,\n",
       "         'hotcakes': 1,\n",
       "         'hottest': 1,\n",
       "         'hug': 1,\n",
       "         'humane': 1,\n",
       "         'humble': 1,\n",
       "         'humility': 1,\n",
       "         'humor': 1,\n",
       "         'humorous': 1,\n",
       "         'humorously': 1,\n",
       "         'humour': 1,\n",
       "         'humourous': 1,\n",
       "         'ideal': 1,\n",
       "         'idealize': 1,\n",
       "         'ideally': 1,\n",
       "         'idol': 1,\n",
       "         'idolize': 1,\n",
       "         'idolized': 1,\n",
       "         'idyllic': 1,\n",
       "         'illuminate': 1,\n",
       "         'illuminati': 1,\n",
       "         'illuminating': 1,\n",
       "         'illumine': 1,\n",
       "         'illustrious': 1,\n",
       "         'ilu': 1,\n",
       "         'imaculate': 1,\n",
       "         'imaginative': 1,\n",
       "         'immaculate': 1,\n",
       "         'immaculately': 1,\n",
       "         'immense': 1,\n",
       "         'impartial': 1,\n",
       "         'impartiality': 1,\n",
       "         'impartially': 1,\n",
       "         'impassioned': 1,\n",
       "         'impeccable': 1,\n",
       "         'impeccably': 1,\n",
       "         'important': 1,\n",
       "         'impress': 1,\n",
       "         'impressed': 1,\n",
       "         'impresses': 1,\n",
       "         'impressive': 1,\n",
       "         'impressively': 1,\n",
       "         'impressiveness': 1,\n",
       "         'improve': 1,\n",
       "         'improved': 1,\n",
       "         'improvement': 1,\n",
       "         'improvements': 1,\n",
       "         'improves': 1,\n",
       "         'improving': 1,\n",
       "         'incredible': 1,\n",
       "         'incredibly': 1,\n",
       "         'indebted': 1,\n",
       "         'individualized': 1,\n",
       "         'indulgence': 1,\n",
       "         'indulgent': 1,\n",
       "         'industrious': 1,\n",
       "         'inestimable': 1,\n",
       "         'inestimably': 1,\n",
       "         'inexpensive': 1,\n",
       "         'infallibility': 1,\n",
       "         'infallible': 1,\n",
       "         'infallibly': 1,\n",
       "         'influential': 1,\n",
       "         'ingenious': 1,\n",
       "         'ingeniously': 1,\n",
       "         'ingenuity': 1,\n",
       "         'ingenuous': 1,\n",
       "         'ingenuously': 1,\n",
       "         'innocuous': 1,\n",
       "         'innovation': 1,\n",
       "         'innovative': 1,\n",
       "         'inpressed': 1,\n",
       "         'insightful': 1,\n",
       "         ...})"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f8314a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "article_file = os.listdir('E:\\Blackcoffer\\parsed_data\\\\')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "18b25ffa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bctech2011.txt',\n",
       " 'bctech2012.txt',\n",
       " 'bctech2013.txt',\n",
       " 'bctech2014.txt',\n",
       " 'bctech2015.txt',\n",
       " 'bctech2016.txt',\n",
       " 'bctech2017.txt',\n",
       " 'bctech2018.txt',\n",
       " 'bctech2019.txt',\n",
       " 'bctech2020.txt',\n",
       " 'bctech2021.txt',\n",
       " 'bctech2022.txt',\n",
       " 'bctech2023.txt',\n",
       " 'bctech2024.txt',\n",
       " 'bctech2025.txt',\n",
       " 'bctech2026.txt',\n",
       " 'bctech2027.txt',\n",
       " 'bctech2028.txt',\n",
       " 'bctech2029.txt',\n",
       " 'bctech2030.txt',\n",
       " 'bctech2031.txt',\n",
       " 'bctech2032.txt',\n",
       " 'bctech2033.txt',\n",
       " 'bctech2034.txt',\n",
       " 'bctech2035.txt',\n",
       " 'bctech2036.txt',\n",
       " 'bctech2037.txt',\n",
       " 'bctech2038.txt',\n",
       " 'bctech2039.txt',\n",
       " 'bctech2040.txt',\n",
       " 'bctech2041.txt',\n",
       " 'bctech2042.txt',\n",
       " 'bctech2043.txt',\n",
       " 'bctech2044.txt',\n",
       " 'bctech2045.txt',\n",
       " 'bctech2046.txt',\n",
       " 'bctech2047.txt',\n",
       " 'bctech2048.txt',\n",
       " 'bctech2049.txt',\n",
       " 'bctech2050.txt',\n",
       " 'bctech2051.txt',\n",
       " 'bctech2052.txt',\n",
       " 'bctech2053.txt',\n",
       " 'bctech2054.txt',\n",
       " 'bctech2055.txt',\n",
       " 'bctech2056.txt',\n",
       " 'bctech2057.txt',\n",
       " 'bctech2058.txt',\n",
       " 'bctech2059.txt',\n",
       " 'bctech2060.txt',\n",
       " 'bctech2061.txt',\n",
       " 'bctech2062.txt',\n",
       " 'bctech2063.txt',\n",
       " 'bctech2064.txt',\n",
       " 'bctech2065.txt',\n",
       " 'bctech2066.txt',\n",
       " 'bctech2067.txt',\n",
       " 'bctech2068.txt',\n",
       " 'bctech2069.txt',\n",
       " 'bctech2070.txt',\n",
       " 'bctech2071.txt',\n",
       " 'bctech2072.txt',\n",
       " 'bctech2073.txt',\n",
       " 'bctech2074.txt',\n",
       " 'bctech2075.txt',\n",
       " 'bctech2076.txt',\n",
       " 'bctech2077.txt',\n",
       " 'bctech2078.txt',\n",
       " 'bctech2079.txt',\n",
       " 'bctech2080.txt',\n",
       " 'bctech2081.txt',\n",
       " 'bctech2082.txt',\n",
       " 'bctech2083.txt',\n",
       " 'bctech2084.txt',\n",
       " 'bctech2085.txt',\n",
       " 'bctech2086.txt',\n",
       " 'bctech2087.txt',\n",
       " 'bctech2088.txt',\n",
       " 'bctech2089.txt',\n",
       " 'bctech2090.txt',\n",
       " 'bctech2091.txt',\n",
       " 'bctech2092.txt',\n",
       " 'bctech2093.txt',\n",
       " 'bctech2094.txt',\n",
       " 'bctech2095.txt',\n",
       " 'bctech2096.txt',\n",
       " 'bctech2097.txt',\n",
       " 'bctech2098.txt',\n",
       " 'bctech2099.txt',\n",
       " 'bctech2100.txt',\n",
       " 'bctech2101.txt',\n",
       " 'bctech2102.txt',\n",
       " 'bctech2103.txt',\n",
       " 'bctech2104.txt',\n",
       " 'bctech2105.txt',\n",
       " 'bctech2106.txt',\n",
       " 'bctech2107.txt',\n",
       " 'bctech2108.txt',\n",
       " 'bctech2109.txt',\n",
       " 'bctech2110.txt',\n",
       " 'bctech2111.txt',\n",
       " 'bctech2112.txt',\n",
       " 'bctech2113.txt',\n",
       " 'bctech2114.txt',\n",
       " 'bctech2115.txt',\n",
       " 'bctech2116.txt',\n",
       " 'bctech2117.txt',\n",
       " 'bctech2118.txt',\n",
       " 'bctech2119.txt',\n",
       " 'bctech2120.txt',\n",
       " 'bctech2121.txt',\n",
       " 'bctech2122.txt',\n",
       " 'bctech2123.txt',\n",
       " 'bctech2124.txt',\n",
       " 'bctech2125.txt',\n",
       " 'bctech2126.txt',\n",
       " 'bctech2127.txt',\n",
       " 'bctech2128.txt',\n",
       " 'bctech2129.txt',\n",
       " 'bctech2130.txt',\n",
       " 'bctech2131.txt',\n",
       " 'bctech2132.txt',\n",
       " 'bctech2133.txt',\n",
       " 'bctech2134.txt',\n",
       " 'bctech2135.txt',\n",
       " 'bctech2136.txt',\n",
       " 'bctech2137.txt',\n",
       " 'bctech2138.txt',\n",
       " 'bctech2139.txt',\n",
       " 'bctech2140.txt',\n",
       " 'bctech2141.txt',\n",
       " 'bctech2142.txt',\n",
       " 'bctech2143.txt',\n",
       " 'bctech2144.txt',\n",
       " 'bctech2145.txt',\n",
       " 'bctech2146.txt',\n",
       " 'bctech2147.txt',\n",
       " 'bctech2148.txt',\n",
       " 'bctech2149.txt',\n",
       " 'bctech2150.txt',\n",
       " 'bctech2151.txt',\n",
       " 'bctech2152.txt',\n",
       " 'bctech2153.txt',\n",
       " 'bctech2154.txt',\n",
       " 'bctech2155.txt',\n",
       " 'bctech2156.txt',\n",
       " 'bctech2157.txt']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8da73f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory  = 'E:\\Blackcoffer\\parsed_data\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "52a0b634",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "URL_ID\n",
      "URL\n",
      "POSITIVE SCORE\n",
      "NEGATIVE SCORE\n",
      "POLARITY SCORE\n",
      "SUBJECTIVITY SCORE\n",
      "AVG SENTENCE LENGTH\n",
      "PERCENTAGE OF COMPLEX WORDS\n",
      "FOG INDEX\n",
      "AVG NUMBER OF WORDS PER SENTENCE\n",
      "COMPLEX WORD COUNT\n",
      "WORD COUNT\n",
      "SYLLABLE PER WORD\n",
      "PERSONAL PRONOUNS\n",
      "AVG WORD LENGTH\n"
     ]
    }
   ],
   "source": [
    "for col in url_df.columns:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71d87bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in article_file:\n",
    "    \n",
    "    url_id = re.sub('.txt', '', file)\n",
    "    file_path = directory + file\n",
    "    result = extract_feature(file_path,  positive_counts, negative_counts)[0]\n",
    "    url_df.loc[(url_df['URL_ID'] == url_id), ['POSITIVE SCORE', \n",
    "'NEGATIVE SCORE', \n",
    "'POLARITY SCORE', \n",
    "'SUBJECTIVITY SCORE', \n",
    "'AVG SENTENCE LENGTH', \n",
    "'PERCENTAGE OF COMPLEX WORDS', \n",
    "'FOG INDEX', \n",
    "'AVG NUMBER OF WORDS PER SENTENCE', \n",
    "'COMPLEX WORD COUNT', \n",
    "'WORD COUNT', \n",
    "'SYLLABLE PER WORD', \n",
    "'PERSONAL PRONOUNS', \n",
    "'AVG WORD LENGTH']] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6664cbc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6455f895",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f2bb37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#url_df.to_csv('E:\\Blackcoffer\\output_file.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34cdfc7c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
